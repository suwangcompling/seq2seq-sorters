{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Ptr-Net second pass\n",
    "\n",
    "* Input: accident and earthquake dataset scrambled documents.\n",
    "* Output: ordered documents.\n",
    "* Gong et al. (2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add custom import path\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/home/jacobsuwang/Documents/UTA2018/NEURAL-NETS/ATTENTION/CODE/01-import-folder')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "README\n",
      "\n",
      "@ 'tar-order':targets_orders\n",
      "\n",
      "List of sentence order lists; each list = integers indexing permuted sentences in the doc.\n",
      "\n",
      "@ 'inp-encode':inputs_encoded\n",
      "\n",
      "List of documents; each doc = a list of sentences; each sent = a list of word indices.\n",
      "\n",
      "@ 'inp-slen':inputs_sent_lengths\n",
      "\n",
      "List of length info of documents; each info = a list of sentence lengths.\n",
      "\n",
      "@ 'w-indexer':word_indexer\n",
      "\n",
      "Indexer() class. word <-> word index.\n",
      "\n",
      "@ 'idx-emb':idx2emb\n",
      "\n",
      "dict() class. index <-> glove embeddings.\n",
      "\n",
      "@ 'glove-init':glove_init\n",
      "\n",
      "Initializer of embedding matrix. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "import dill\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "bl08_path = '/home/jacobsuwang/Documents/UTA2018/NEURAL-NETS/ATTENTION/DATA/COHERENCE/data1-train-encoded-data.p'\n",
    "\n",
    "data_dict = dill.load(open(bl08_path, 'rb'))\n",
    "\n",
    "print data_dict['readme']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 3, 4, 3, 5, 6, 7, 8, 9, 10, 6, 11, 12, 13], [14, 15, 4, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 10, 19, 32, 6, 11, 33, 13], [34, 30, 35, 36, 37, 38, 39, 40, 41, 42, 6, 15, 29, 43, 19, 44, 45, 37, 46, 13], [11, 33, 47, 6, 48, 49, 50, 51, 52, 53, 37, 25, 28, 37, 54, 15, 55, 56, 16, 57, 58, 18, 59, 37, 42, 60, 61, 13], [53, 62, 43, 63, 14, 64, 65, 15, 51, 42, 66, 67, 30, 68, 42, 69, 70, 71, 13], [4, 47, 72, 73, 74, 51, 75, 76, 74, 77, 78, 79, 21, 3, 80, 81, 82, 83, 42, 84, 85, 13], [16, 86, 3, 87, 18]]\n"
     ]
    }
   ],
   "source": [
    "print data_dict['inp-encode'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61 26\n"
     ]
    }
   ],
   "source": [
    "max_sent, max_doc = 0, 0\n",
    "for doc in data_dict['inp-encode']:\n",
    "    if len(doc)>max_doc:\n",
    "        max_doc = len(doc)\n",
    "    for sent in doc:\n",
    "        if len(sent)>max_sent:\n",
    "            max_sent = len(sent)\n",
    "print max_sent, max_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Padding inputs\n",
    "\n",
    "MAX_SENT = 61\n",
    "MAX_DOC = 26\n",
    "\n",
    "data_inputs = []\n",
    "\n",
    "def pad_doc(doc):\n",
    "    padded_doc = []\n",
    "    doc_length = len(doc)\n",
    "    for sent in doc:\n",
    "        padded_sent = sent + [0]*(MAX_SENT-len(sent))\n",
    "        padded_doc.append(padded_sent)\n",
    "    padded_doc += [[0]*MAX_SENT]*(MAX_DOC-doc_length)\n",
    "    return padded_doc, doc_length\n",
    "\n",
    "def pad_sents_length(slen):\n",
    "    return slen + [0]*(MAX_DOC-len(slen))\n",
    "\n",
    "def pad_tars_order(tord):\n",
    "    return tord + [0]*3 # +1 EOS, +2 PADs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAKE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.rnn import LSTMCell, LSTMStateTuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "sent_emb_size = 20\n",
    "doc_enc_emb_size = sent_emb_size*2\n",
    "doc_dec_emb_size = doc_enc_emb_size*2\n",
    "\n",
    "sent_vocab_size = MAX_DOC + 2 # 26 + PAD + EOS.\n",
    "\n",
    "doc_inputs = tf.placeholder(tf.int32, shape=[MAX_DOC, MAX_SENT], name='doc-inputs')\n",
    "    # MAX_DOC: pseudo-batch-size\n",
    "    # MAX_SENT: pseudo-max-time.\n",
    "doc_sents_length = tf.placeholder(tf.int32, shape=[MAX_DOC], name='doc-sents-length')\n",
    "\n",
    "embeddings = tf.get_variable('word-embeddings', shape=data_dict['glove-init'].shape, # (1809,300)\n",
    "                             initializer=tf.constant_initializer())\n",
    "glove_feed = tf.placeholder(tf.float32, shape=data_dict['glove-init'].shape)\n",
    "glove_init = embeddings.assign(glove_feed)\n",
    "doc_inputs_embedded = tf.transpose(tf.nn.embedding_lookup(embeddings, doc_inputs),[1,0,2]) \n",
    "    # (61, 26, 300), (mt,bc,emb), time-major\n",
    "\n",
    "with tf.variable_scope('sent-enc'):\n",
    "    sent_enc_cell = LSTMCell(sent_emb_size)\n",
    "    ((sent_enc_fw_outputs,sent_enc_bw_outputs), \n",
    "     (sent_enc_fw_final_state,sent_enc_bw_final_state)) = ( \n",
    "            tf.nn.bidirectional_dynamic_rnn(cell_fw=sent_enc_cell,\n",
    "                                            cell_bw=sent_enc_cell,\n",
    "                                            inputs=doc_inputs_embedded,\n",
    "                                            sequence_length=doc_sents_length,\n",
    "                                            dtype=tf.float32, time_major=True)\n",
    "        )\n",
    "    sent_enc_outputs = tf.concat((sent_enc_fw_outputs,sent_enc_bw_outputs), 2) \n",
    "        # <tf.Tensor 'sent-enc/concat:0' shape=(61, 26, 40) dtype=float32>\n",
    "    sent_enc_final_state_c = tf.concat((sent_enc_fw_final_state.c,sent_enc_bw_final_state.c), 1)\n",
    "    sent_enc_final_state_h = tf.concat((sent_enc_fw_final_state.c,sent_enc_bw_final_state.h), 1)\n",
    "    sent_enc_final_state = LSTMStateTuple(\n",
    "        c=sent_enc_final_state_c,\n",
    "        h=sent_enc_final_state_h\n",
    "    )    \n",
    "        # LSTMStateTuple(c=<tf.Tensor 'sent-enc/concat_1:0' shape=(?, 40) dtype=float32>, \n",
    "        #                h=<tf.Tensor 'sent-enc/concat_2:0' shape=(?, 40) dtype=float32>)\n",
    "        # .h should be (bc=MAX_DOC,emb), but why it gives \"?\"?\n",
    "        \n",
    "## TEST ##\n",
    "\n",
    "# sess.run(tf.global_variables_initializer())\n",
    "# doc_inputs_, _ = pad_doc(data_dict['inp-encode'][0]) # _ is doc_length, used later.\n",
    "# doc_sents_length_ = pad_sents_length(data_dict['inp-slen'][0])\n",
    "# fd = {doc_inputs:doc_inputs_, doc_sents_length:doc_sents_length_,\n",
    "#       glove_feed:data_dict['glove-init']}\n",
    "# t1, t2 = sess.run([sent_enc_outputs, sent_enc_final_state], feed_dict=fd)\n",
    "\n",
    "# assert 1==0\n",
    "        \n",
    "doc_final_embedded = tf.expand_dims(sent_enc_final_state.h, 1)\n",
    "    # <tf.Tensor 'ExpandDims:0' shape=(?, 1, 40) dtype=float32>\n",
    "    # (mt=#sents in doc, bc=1, emb)\n",
    "    # e.g. (26, 1, 40)\n",
    "doc_length = tf.placeholder(tf.int32, shape=[1], name='doc-length')\n",
    "# doc_targets = tf.placeholder(tf.int32, shape=[MAX_DOC], name='doc-targets')\n",
    "doc_targets = tf.placeholder(tf.int32, shape=[None, 1], name='doc-targets') # [mt,bc]\n",
    "# data_dict['tar-order'][0]\n",
    "\n",
    "with tf.variable_scope('doc-enc'):\n",
    "    doc_enc_cell = LSTMCell(doc_enc_emb_size)\n",
    "    ((doc_enc_fw_outputs,doc_enc_bw_outputs), \n",
    "     (doc_enc_fw_final_state,doc_enc_bw_final_state)) = ( \n",
    "            tf.nn.bidirectional_dynamic_rnn(cell_fw=doc_enc_cell,\n",
    "                                            cell_bw=doc_enc_cell,\n",
    "                                            inputs=doc_final_embedded,\n",
    "                                            sequence_length=doc_length,\n",
    "                                            dtype=tf.float32, time_major=True)\n",
    "        )    \n",
    "    doc_enc_outputs = tf.concat((doc_enc_fw_outputs,doc_enc_bw_outputs), 2) \n",
    "        # <tf.Tensor 'doc-enc/concat:0' shape=(?, 1, 80) dtype=float32>\n",
    "    doc_enc_final_state_c = tf.concat((doc_enc_fw_final_state.c,doc_enc_bw_final_state.c), 1)\n",
    "    doc_enc_final_state_h = tf.concat((doc_enc_fw_final_state.c,doc_enc_bw_final_state.h), 1)\n",
    "    doc_enc_final_state = LSTMStateTuple(\n",
    "        c=doc_enc_final_state_c,\n",
    "        h=doc_enc_final_state_h\n",
    "    )\n",
    "        # LSTMStateTuple(c=<tf.Tensor 'doc-enc/concat_1:0' shape=(?, 80) dtype=float32>, \n",
    "        #                h=<tf.Tensor 'doc-enc/concat_2:0' shape=(?, 80) dtype=float32>)\n",
    "        # .h should be (bc, emb)\n",
    "        \n",
    "## TEST ##\n",
    "\n",
    "# sess.run(tf.global_variables_initializer())\n",
    "# doc_inputs_, _ = pad_doc(data_dict['inp-encode'][0]) # _ is doc_length, used later.\n",
    "# doc_sents_length_ = pad_sents_length(data_dict['inp-slen'][0])\n",
    "# doc_length_ = [len(data_dict['inp-encode'][0])] # NB: must be [1]!!!\n",
    "# fd = {doc_inputs:doc_inputs_, doc_sents_length:doc_sents_length_,\n",
    "#       doc_length:doc_length_,\n",
    "#       glove_feed:data_dict['glove-init']}\n",
    "# t3, t4 = sess.run([doc_enc_outputs, doc_enc_final_state], feed_dict=fd)\n",
    "\n",
    "# assert 1==0\n",
    "\n",
    "\n",
    "doc_dec_cell = LSTMCell(doc_dec_emb_size)\n",
    "doc_max_time, doc_batch_size, _ = tf.unstack(tf.shape(doc_final_embedded))\n",
    "doc_dec_length = doc_length + 3 # +2 steps, +1 for EOS. i.e. 26 + 3 = 29\n",
    "\n",
    "## TEST ##\n",
    "\n",
    "# sess.run(tf.global_variables_initializer())\n",
    "# doc_inputs_, _ = pad_doc(data_dict['inp-encode'][0]) # _ is doc_length, used later.\n",
    "# doc_sents_length_ = pad_sents_length(data_dict['inp-slen'][0])\n",
    "# doc_length_ = [len(data_dict['inp-encode'][0])] # NB: must be [1]!!!\n",
    "# fd = {doc_inputs:doc_inputs_, doc_sents_length:doc_sents_length_,\n",
    "#       doc_length:doc_length_,\n",
    "#       glove_feed:data_dict['glove-init']}\n",
    "# t5, t6 = sess.run([doc_final_embedded, doc_max_time], feed_dict=fd)\n",
    "\n",
    "# assert 1==0\n",
    "\n",
    "\n",
    "W = tf.Variable(tf.random_uniform([doc_dec_emb_size, sent_vocab_size], -1, 1), dtype=tf.float32) # for dec only!\n",
    "b = tf.Variable(tf.zeros([sent_vocab_size]), dtype=tf.float32)\n",
    "\n",
    "eos_step_embedded = tf.ones([doc_batch_size, doc_enc_emb_size], dtype=tf.float32, name='EOS')\n",
    "pad_step_embedded = tf.zeros([doc_batch_size, doc_enc_emb_size], dtype=tf.float32, name='PAD')\n",
    "\n",
    "def loop_fn_initial():\n",
    "    initial_elements_finished = (0 >= doc_dec_length) \n",
    "    initial_input = eos_step_embedded                   \n",
    "    initial_cell_state = doc_enc_final_state\n",
    "    initial_cell_output = None \n",
    "    initial_loop_state = None \n",
    "    return (initial_elements_finished,\n",
    "            initial_input,\n",
    "            initial_cell_state,\n",
    "            initial_cell_output,\n",
    "            initial_loop_state)\n",
    "\n",
    "# TODO: adjust dimensions later\n",
    "W1 = tf.Variable(tf.random_uniform([doc_enc_emb_size, doc_enc_emb_size], -1, 1),\n",
    "                 dtype=tf.float32) \n",
    "W2 = tf.Variable(tf.random_uniform([doc_dec_emb_size, doc_enc_emb_size], -1, 1), \n",
    "                 dtype=tf.float32) \n",
    "v = tf.Variable(tf.random_uniform([doc_enc_emb_size, 1], -1, 1),\n",
    "                dtype=tf.float32) \n",
    "\n",
    "def loop_fn_transition(time, previous_output, previous_state, previous_loop_state):\n",
    "    \n",
    "    def get_next_input(): \n",
    "        \n",
    "        mt, bc, _ = tf.unstack(tf.shape(doc_final_embedded))\n",
    "        # mt here is for #sents-in-doc!!\n",
    "#         print doc_final_embedded\n",
    "#         assert 1==0\n",
    "#         Tensor(\"ExpandDims:0\", shape=(?, 1, 40), dtype=float32)\n",
    "        \n",
    "        EW1 = tf.reshape(tf.tensordot(doc_final_embedded, W1, axes=[[2],[0]]),\n",
    "                         [mt, bc, doc_enc_emb_size]) \n",
    "#         print EW1\n",
    "#         assert 1==0\n",
    "#         Tensor(\"rnn/while/cond/Reshape:0\", shape=(?, ?, 40), dtype=float32)\n",
    "        \n",
    "        DW2 = tf.matmul(previous_state.h, W2) \n",
    "#         print DW2\n",
    "#         assert 1==0\n",
    "#         Tensor(\"rnn/while/cond/MatMul:0\", shape=(?, 40), dtype=float32)\n",
    "        \n",
    "        EW1_add_DW2 = tf.add(EW1, DW2)\n",
    "#         print EW1_add_DW2\n",
    "#         assert 1==0\n",
    "#         Tensor(\"rnn/while/cond/Add:0\", shape=(?, ?, 40), dtype=float32)\n",
    "        \n",
    "        attention_mat = tf.reshape(tf.nn.tanh(tf.squeeze(tf.tensordot(EW1_add_DW2, v, axes=[[2],[0]]), \n",
    "                                                         axis=2)), [mt,bc])\n",
    "#         print attention_mat\n",
    "#         assert 1==0\n",
    "#         Tensor(\"rnn/while/cond/Reshape_1:0\", shape=(?, ?), dtype=float32) [mt,bc]\n",
    "        \n",
    "        attention_norm_mat = tf.nn.softmax(attention_mat, dim=0) \n",
    "#         print attention_norm_mat\n",
    "#         assert 1==0\n",
    "#         Tensor(\"rnn/while/cond/transpose_1:0\", shape=(?, ?), dtype=float32) [mt,bc]\n",
    "        \n",
    "        \n",
    "        selector = tf.one_hot(tf.argmax(attention_norm_mat, axis=0), depth=doc_max_time,\n",
    "                              on_value=1.0, off_value=0.0, axis=0) \n",
    "#         print selector\n",
    "#         assert 1==0\n",
    "#         Tensor(\"rnn/while/cond/one_hot:0\", shape=(?, ?), dtype=float32)\n",
    "        \n",
    "        inputs_embedded_selected = tf.transpose(\n",
    "            tf.multiply(\n",
    "                tf.transpose(doc_final_embedded, [2,0,1]), \n",
    "                selector), \n",
    "            [1,2,0]\n",
    "        ) \n",
    "#         print inputs_embedded_selected\n",
    "#         assert 1==0\n",
    "#         Tensor(\"rnn/while/cond/transpose_3:0\", shape=(?, ?, 40), dtype=float32)\n",
    "        \n",
    "        inputs_embedded_selected = tf.reduce_sum(\n",
    "            tf.reshape(inputs_embedded_selected, [mt, bc, doc_enc_emb_size]), \n",
    "            axis=0 \n",
    "        )   \n",
    "#         print previous_output\n",
    "#         print inputs_embedded_selected\n",
    "#         assert 1==0\n",
    "#         Tensor(\"rnn/while/lstm_cell/mul_2:0\", shape=(?, 80), dtype=float32)\n",
    "#         Tensor(\"rnn/while/cond/Sum:0\", shape=(?, 40), dtype=float32)\n",
    "        \n",
    "        next_input = inputs_embedded_selected\n",
    "        return next_input\n",
    "    \n",
    "    elements_finished = (time >= doc_dec_length)\n",
    "    finished = tf.reduce_all(elements_finished) \n",
    "    inpt = tf.cond(finished, lambda: pad_step_embedded, get_next_input)\n",
    "    state = previous_state\n",
    "    output = previous_output\n",
    "    loop_state = None\n",
    "    return (elements_finished,\n",
    "            inpt, \n",
    "            state,\n",
    "            output,\n",
    "            loop_state)        \n",
    "\n",
    "def loop_fn(time, previous_output, previous_state, previous_loop_state):\n",
    "    if previous_state is None:\n",
    "        assert previous_output is None and previous_state is None\n",
    "        return loop_fn_initial()\n",
    "    else:\n",
    "        return loop_fn_transition(time, previous_output, previous_state, previous_loop_state)\n",
    "\n",
    "# k = tf.nn.raw_rnn(doc_dec_cell, loop_fn)\n",
    "# print k\n",
    "# assert 1==0\n",
    "    \n",
    "doc_dec_outputs_ta, doc_dec_final_state, _ = tf.nn.raw_rnn(doc_dec_cell, loop_fn)\n",
    "doc_dec_outputs = doc_dec_outputs_ta.stack()\n",
    "# print doc_dec_outputs\n",
    "# Tensor(\"TensorArrayStack/TensorArrayGatherV3:0\", shape=(?, ?, 80), dtype=float32)\n",
    "doc_dec_max_step, doc_dec_batch_size, doc_dec_dim = tf.unstack(tf.shape(doc_dec_outputs))\n",
    "doc_dec_outputs_flat = tf.reshape(doc_dec_outputs, (-1, doc_dec_dim))\n",
    "\n",
    "# print doc_dec_outputs_flat\n",
    "# print doc_dec_dim\n",
    "# assert 1==0\n",
    "\n",
    "doc_dec_logits_flat = tf.add(tf.matmul(doc_dec_outputs_flat, W), b)\n",
    "\n",
    "# print doc_dec_logits_flat\n",
    "\n",
    "doc_dec_logits = tf.reshape(doc_dec_logits_flat, (doc_dec_max_step, doc_dec_batch_size, sent_vocab_size))\n",
    "\n",
    "# print doc_dec_logits\n",
    "# assert 1==0\n",
    "\n",
    "doc_dec_prediction = tf.cast(tf.argmax(doc_dec_logits, 2), dtype=tf.int32)\n",
    "\n",
    "# print doc_dec_prediction\n",
    "\n",
    "## TEST ##\n",
    "\n",
    "# sess.run(tf.global_variables_initializer())\n",
    "# doc_inputs_, _ = pad_doc(data_dict['inp-encode'][1]) # _ is doc_length, used later.\n",
    "# doc_sents_length_ = pad_sents_length(data_dict['inp-slen'][1])\n",
    "# doc_length_ = [len(data_dict['inp-encode'][1])] # NB: must be [2]!!!\n",
    "# doc_targets_ = np.array(pad_tars_order(data_dict['tar-order'][1]))[:,np.newaxis]\n",
    "# fd = {doc_inputs:doc_inputs_, doc_sents_length:doc_sents_length_,\n",
    "#       doc_length:doc_length_, \n",
    "#       doc_targets:doc_targets_,\n",
    "#       glove_feed:data_dict['glove-init']}\n",
    "# t7, t8 = sess.run([doc_dec_outputs, doc_targets], feed_dict=fd)\n",
    "# print t7.shape\n",
    "# print t8.shape\n",
    "# print sess.run([doc_dec_max_step, doc_dec_batch_size, doc_dec_dim], feed_dict=fd)\n",
    "# t7, t8 = sess.run([doc_dec_prediction, doc_targets], feed_dict=fd)\n",
    "# print t7\n",
    "# print t7.shape\n",
    "# print t8\n",
    "# print t8.shape\n",
    "# assert 1==0\n",
    "\n",
    "# Accuracy\n",
    "correct_raw = tf.cast(tf.equal(doc_dec_prediction, doc_targets), tf.int32)\n",
    "\n",
    "# print doc_dec_prediction\n",
    "# print doc_targets\n",
    "# print correct_raw\n",
    "# assert 1==0\n",
    "\n",
    "mask = tf.cast(tf.not_equal(doc_targets, 0), tf.int32) # 0 for PAD\n",
    "total_seqlen = tf.cast(doc_length, tf.float32)\n",
    "correct = tf.multiply(correct_raw, mask)\n",
    "accuracy = tf.cast(tf.reduce_sum(correct)-1, tf.float32) / total_seqlen # batch_size = 1\n",
    "\n",
    "## TEST ##\n",
    "\n",
    "# sess.run(tf.global_variables_initializer())\n",
    "# doc_inputs_, _ = pad_doc(data_dict['inp-encode'][1]) # _ is doc_length, used later.\n",
    "# doc_sents_length_ = pad_sents_length(data_dict['inp-slen'][1])\n",
    "# doc_length_ = [len(data_dict['inp-encode'][1])] # NB: must be [2]!!!\n",
    "# doc_targets_ = np.array(pad_tars_order(data_dict['tar-order'][1]))[:,np.newaxis]\n",
    "# fd = {doc_inputs:doc_inputs_, doc_sents_length:doc_sents_length_,\n",
    "#       doc_length:doc_length_, \n",
    "#       doc_targets:doc_targets_,\n",
    "#       glove_feed:data_dict['glove-init']}\n",
    "# t9,t10,t11 = sess.run([doc_dec_prediction, doc_targets, accuracy], feed_dict=fd)\n",
    "# print t9\n",
    "# print t10\n",
    "# print t11\n",
    "\n",
    "# Optimization\n",
    "stepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=tf.one_hot(doc_targets, depth=sent_vocab_size, dtype=tf.float32),\n",
    "    logits=doc_dec_logits\n",
    ")\n",
    "loss = tf.reduce_mean(stepwise_cross_entropy)\n",
    "train_op = tf.train.AdamOptimizer().minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2035\n",
      "2035\n",
      "2035\n"
     ]
    }
   ],
   "source": [
    "print len(data_dict['inp-encode'])\n",
    "print len(data_dict['inp-slen'])\n",
    "print len(data_dict['tar-order'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "\n",
      "Current mean loss = 0.00481224153191 | mean accuracy = 0.857142865658\n",
      "Current mean loss = 0.83429569006 | mean accuracy = 0.551808357239\n",
      "Current mean loss = 0.810026943684 | mean accuracy = 0.561738312244\n",
      "Current mean loss = 0.683873176575 | mean accuracy = 0.601092517376\n",
      "Current mean loss = 0.686348259449 | mean accuracy = 0.597848057747\n",
      "\n",
      "Epoch 2:\n",
      "\n",
      "Current mean loss = 0.677813529968 | mean accuracy = 0.600679934025\n",
      "Current mean loss = 0.700254976749 | mean accuracy = 0.594907283783\n",
      "Current mean loss = 0.708626627922 | mean accuracy = 0.5940528512\n",
      "Current mean loss = 0.665521979332 | mean accuracy = 0.607996881008\n",
      "Current mean loss = 0.665780544281 | mean accuracy = 0.607267439365\n",
      "\n",
      "Epoch 3:\n",
      "\n",
      "Current mean loss = 0.661509215832 | mean accuracy = 0.608664155006\n",
      "Current mean loss = 0.673916637897 | mean accuracy = 0.605031013489\n",
      "Current mean loss = 0.679312288761 | mean accuracy = 0.604320406914\n",
      "Current mean loss = 0.652481198311 | mean accuracy = 0.612894177437\n",
      "Current mean loss = 0.652696311474 | mean accuracy = 0.612235605717\n",
      "\n",
      "Epoch 4:\n",
      "\n",
      "Current mean loss = 0.649781286716 | mean accuracy = 0.613240718842\n",
      "Current mean loss = 0.657254219055 | mean accuracy = 0.611529052258\n",
      "Current mean loss = 0.660265803337 | mean accuracy = 0.611588180065\n",
      "Current mean loss = 0.640904664993 | mean accuracy = 0.617809951305\n",
      "Current mean loss = 0.641308188438 | mean accuracy = 0.617592990398\n",
      "\n",
      "Epoch 5:\n",
      "\n",
      "Current mean loss = 0.639063060284 | mean accuracy = 0.618369817734\n",
      "Current mean loss = 0.644090354443 | mean accuracy = 0.617392122746\n",
      "Current mean loss = 0.646939575672 | mean accuracy = 0.617114782333\n",
      "Current mean loss = 0.631752789021 | mean accuracy = 0.622001111507\n",
      "Current mean loss = 0.6305590868 | mean accuracy = 0.62205439806\n",
      "\n",
      "Epoch 6:\n",
      "\n",
      "Current mean loss = 0.6287509799 | mean accuracy = 0.622697472572\n",
      "Current mean loss = 0.632335841656 | mean accuracy = 0.621980905533\n",
      "Current mean loss = 0.634101688862 | mean accuracy = 0.62212395668\n",
      "Current mean loss = 0.621536254883 | mean accuracy = 0.626137673855\n",
      "Current mean loss = 0.620187580585 | mean accuracy = 0.626414418221\n",
      "\n",
      "Epoch 7:\n",
      "\n",
      "Current mean loss = 0.618668615818 | mean accuracy = 0.626978695393\n",
      "Current mean loss = 0.621141672134 | mean accuracy = 0.626759946346\n",
      "Current mean loss = 0.622605741024 | mean accuracy = 0.626659929752\n",
      "Current mean loss = 0.61210745573 | mean accuracy = 0.630007505417\n",
      "Current mean loss = 0.61085319519 | mean accuracy = 0.630361974239\n",
      "\n",
      "Epoch 8:\n",
      "\n",
      "Current mean loss = 0.60958981514 | mean accuracy = 0.630809664726\n",
      "Current mean loss = 0.611749112606 | mean accuracy = 0.630412757397\n"
     ]
    }
   ],
   "source": [
    "loss_track = []\n",
    "accuracy_track = []\n",
    "\n",
    "num_epochs = 100\n",
    "verbose = 500\n",
    "\n",
    "sess.run(glove_feed, feed_dict={glove_feed:data_dict['glove-init']})\n",
    "\n",
    "for e in range(num_epochs):\n",
    "    print 'Epoch {}:'.format(e+1)\n",
    "    print\n",
    "    for i in range(len(data_dict['inp-encode'])):\n",
    "        doc_inputs_, _ = pad_doc(data_dict['inp-encode'][i])\n",
    "        doc_sents_length_ = pad_sents_length(data_dict['inp-slen'][i])\n",
    "        doc_length_ = [len(data_dict['inp-encode'][i])] # NB: must be [2]!!!\n",
    "        doc_targets_ = np.array(pad_tars_order(data_dict['tar-order'][i]))[:,np.newaxis]\n",
    "        fd = {doc_inputs:doc_inputs_, \n",
    "              doc_sents_length:doc_sents_length_,\n",
    "              doc_length:doc_length_, \n",
    "              doc_targets:doc_targets_}\n",
    "        _, l, a = sess.run([train_op, loss, accuracy], feed_dict=fd)\n",
    "        loss_track.append(l)\n",
    "        accuracy_track.append(a)\n",
    "        if i % verbose == 0:\n",
    "            print 'Current mean loss = {} | mean accuracy = {}'.format(np.mean(loss_track),np.mean(accuracy_track))\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
